{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 аттрибута тензора в pytorch:\n",
    "\n",
    "dtype - тип данных хранимых в тензоре (float32, etc.)\n",
    "\n",
    "device - на чём обрабатывается данный тензор (тензоры которые взаимодействую должны быть на одном проце/видяхе)\n",
    "\n",
    "layout - как данные расположены в памяти (не трогай это, дефолтная настройка норм)\n",
    "\n",
    "# Создание тензоров (прямо как в NumPy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# единичный тензор\n",
    "print(torch.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нулевой\n",
    "torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# единичный\n",
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание тензоров из данных:\n",
    "\n",
    "Factory function has more tweaking parameters than class constructor, so we will use them more often. They also infere the dtype (they get data in i.e. int32, they save it as int32).\n",
    "\n",
    "Beware that torch.Tensor and torch.tensor CREATE a copy of input data in memory, when torch.as_tensor and torch.from_numpy just mirror the existing data (so the last is more memory efficient, but if the original data is changed, tensor changed too. Data MUST be in NumPy array).\n",
    "\n",
    "For casual use - torch.tensor()\n",
    "\n",
    "For speed boost - torch.as_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,2,3])\n",
    "\n",
    "t1 = torch.Tensor(data) # class constructor\n",
    "t2 = torch.tensor(data) # factory function\n",
    "t3 = torch.as_tensor(data) # factory function\n",
    "t4 = torch.from_numpy(data) # factory function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping the the tensors, squeezing\n",
    "\n",
    ".reshape() or .view()(одно и то же, просто разные названия) - прямое изменение размеров тензора\n",
    "\n",
    ".squeeze() - удаление всех осей с длинной 1.\n",
    "\n",
    ".unsqueeze() - добавляет ось с длиной 1, это позволяет изменять ранг тензора.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "], dtype=torch.float32)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# number of elements check\n",
    "print(torch.tensor(t.shape).prod())\n",
    "print(t.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 3.],\n",
      "          [3., 3., 3.]]]])\n",
      "tensor([[1., 1., 1., 1., 2., 2.],\n",
      "        [2., 2., 3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(2, 1, 2, 3)) # reshape to rank-4 tensor (from rank-2)\n",
    "print(t.reshape(2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n",
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12)) # tensor rank 2\n",
    "print(t.reshape(1,12).squeeze()) # tensor rank 1\n",
    "\n",
    "# маленький трюк - если не знаем сколько компонентов будет в тензоре который мы хотим\n",
    "# \"вытянуть\" сохранив второй ранг мы пишем \"1, -1\" во втором атрибуте .reshape\n",
    "print(t.reshape(1,-1))\n",
    "\n",
    "# если хотим перевести его в тензор первого ранга пишем \"-1\"\n",
    "print(t.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening, Tensor size for neural network\n",
    "\n",
    ".flatten() - позволяет зарешейпить тензор любого ранга в тензор первого ранга\n",
    "\n",
    "Однако для нейросети абсолютно \"плоские\" данные нам не нужны, т.к. она должна различать batch (какие данные к какой введённой переменой относятся).\n",
    "\n",
    "Нейронка работает с тензорами ранга 4, вот что каждая из осей представляет(на примере тензора ниже):\n",
    "\n",
    "Batch - contains 3 images\n",
    "\n",
    "Image - contains 1 color channel (cause grayscale)\n",
    "\n",
    "Color channel - contains 4 arrays(rows/hight)\n",
    "\n",
    "4 arrays(rows/hight) - contains 4 pixel values (columns/width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 3 \"images\" 4x4 pixels, grayscale\n",
    "\n",
    "t1 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "])\n",
    "t2 = torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])\n",
    "t3 = torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])\n",
    "\n",
    "# stack them to make a tensor with rank 3 (new axis represents batch), now we have a 3\n",
    "# \"grayscale\" pictures in the resulting tensor\n",
    "t = torch.stack((t1, t2, t3))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2]]],\n",
       "\n",
       "\n",
       "        [[[3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and a new axis to this tensor to create a \"batch\" axis for discening the \"pictures\"\n",
    "t = t.reshape(3, 1, 4, 4)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to use flatten\n",
    "\n",
    "We can't flatten the whole tensor, cause it will become a simple vector and we won't be able to know where are the \"start\" and the \"end\" of each \"picture\". So we flatten this tensor in such a way that wa preserve the \"batch\" axis (flattening the color channel with hight and width axes), which tells us which \"picture\" is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad  -  torch.Size([48])\n",
      "good -  torch.Size([3, 16])\n"
     ]
    }
   ],
   "source": [
    "# bad idea - got vector with 48 pixel, no way to know from which picture each pixel comes from\n",
    "a = t.flatten()\n",
    "print('bad  - ', a.shape)\n",
    "\n",
    "# good idea - got 3 images with 16 pixels\n",
    "t = t.flatten(start_dim=1) # start flattening from axis=1 (it`s an index)\n",
    "print('good - ', t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting for element-wise operations\n",
    "\n",
    "Broadcasting is transforming a lower rank tensor to match the shape of the tensor with which we want it to perform an element-wise operation.\n",
    "\n",
    "All element-wise operations works with tensors due to the broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])\n",
      "tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]])\n",
      "tensor([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "        [-2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2],\n",
      "        [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3]])\n"
     ]
    }
   ],
   "source": [
    "print(t.eq(1)) # equal 1\n",
    "print(t.abs()) # взятие модуля\n",
    "print(t + 3)\n",
    "print(t.neg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction operation - .ArgMax()\n",
    "\n",
    "Reduction operation on tensor is an operation that reduced the number of elements contained within the tensor.\n",
    "\n",
    "We can use .mean(),\n",
    "\n",
    ".argmax() returns the index of the max value inside the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor(8.)\n",
      "tensor([2., 4., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.tensor([\n",
    "    [0,1,0],\n",
    "    [2,0,2],\n",
    "    [0,3,0]\n",
    "], dtype=torch.float32)\n",
    "print(t4.shape)\n",
    "\n",
    "print(t4.sum()) # sum all elements = reduce this tensor to one axis\n",
    "print(t4.sum(dim=0))\n",
    "print(t4.sum(dim=0).shape) # sum along axis 1 (sum columns) = reduce this tensor to one axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value   =  tensor(3.)\n",
      "flatten =  tensor([0., 1., 0., 2., 0., 2., 0., 3., 0.])\n",
      "index   =  tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print('value   = ', t4.max())     # MAX value \n",
    "print('flatten = ', t4.flatten()) # flatten tensor (count indices from '0')\n",
    "print('index   = ', t4.argmax())  # index of the MAX value (yep, '3' has index=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2., 3., 2.]),\n",
      "indices=tensor([1, 2, 1])) \n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([1, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(t4.max(dim=0), '\\n') # max values on axis=0\n",
    "print(t4.max(dim=1)) # first tensor - max values, second tensor - their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8889)\n",
      "0.8888888955116272 \n",
      "\n",
      "tensor([0.6667, 1.3333, 0.6667])\n",
      "[0.6666666865348816, 1.3333333730697632, 0.6666666865348816] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if we wanna get the results not as tensors, but as ints/floats/np.arrays:\n",
    "\n",
    "print(t4.mean())             # got tensor\n",
    "print(t4.mean().item(), '\\n') # got float32\n",
    "\n",
    "print(t4.mean(dim=0))                # got tensor\n",
    "print(t4.mean(dim=0).tolist(), '\\n') # got np.array of float32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
