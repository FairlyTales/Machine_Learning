{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "Handling missing values is an essential preprocessing task that can drastically deteriorate your model when not done with sufficient care. A few questions should come up when handling missing values:\n",
    "\n",
    "Do I have missing values? How are they expressed in the data? Should I withhold samples with missing values? Or should I replace them? If so, which values should they be replaced with?\n",
    "\n",
    "Before starting handling missing values it is important to identify the missing values and know with which value they are replaced. You should be able to find this out by combining the metadata information with exploratory analysis.\n",
    "\n",
    "Once you know a bit more about the missing data you have to decide whether or not you want to keep entries with missing data. According to Chris Albon (Machine Learning with Python Cookbook), this decision should partially depend on how random missing values are.\n",
    "\n",
    "If they are completely at random, they don’t give any extra information and can be omitted. On the other hand, if they’re not at random, the fact that a value is missing is itself information and can be expressed as an extra binary feature.\n",
    "\n",
    "Also keep in mind that deleting a whole observation because it has one missing value, might be a poor decision and lead to information loss. Just like keeping a whole row of missing values because it has a meaningful missing value might not be your best move.\n",
    "\n",
    "Let’s materialize this theory with some coding examples using sklearn’s MissingIndicator. To give our code some meaning, we’ll create a very small data set with three features and five samples. The data contains obvious missing values expressed as not-a-number or 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1   f2    f3\n",
       "0    5.0  7.0   8.0\n",
       "1    NaN  NaN   NaN\n",
       "2   -5.0  0.0  25.0\n",
       "3  999.0  1.0  -1.0\n",
       "4    NaN  0.0   NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame(np.array([5,7,8, np.NaN, np.NaN, np.NaN, -5,\n",
    "                           0,25,999,1,-1, np.NaN, 0, np.NaN])\n",
    "                 .reshape((5,3)))\n",
    "X.columns = ['f1', 'f2', 'f3'] #feature 1, feature 2, feature 3\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the data so you know where the missing values are situated. Rows or columns with to many non-meaningful missing values can be deleted from you data with pandas’ dropna function. Let take a look at the most important parameters:\n",
    "\n",
    "    axis: 0 for rows, 1 for columns\n",
    "    tresh: the number of non-NaN’s not to drop a row or column\n",
    "    inplace: update the frame\n",
    "\n",
    "We update our dataset by deleting all the rows (axis=0) with only missing values. Note that in this case instead of setting tresh to 1, you can also set the how parameter to ‘all’. As a result our second sample is dropped, since it only consist of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1   f2    f3\n",
       "0    5.0  7.0   8.0\n",
       "1   -5.0  0.0  25.0\n",
       "2  999.0  1.0  -1.0\n",
       "3    NaN  0.0   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna(axis='rows', thresh=1, inplace=True)\n",
    "X.reset_index(inplace=True)\n",
    "\n",
    "# сброс старого индекса, если это не сделать, будет 2 столбца индексов\n",
    "X.drop(['index'], axis='columns', inplace=True)\n",
    "\n",
    "# не обращай внимания на это строчку, она нужна для примера который будет дальше\n",
    "Y = X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим булевы features говорящие о том есть ли в sample пустые значения, используя MissingIndicator.\n",
    "\n",
    "Т.к. он не поддерживает множественные типы пустых значений мы преобразовываем значение 999 в NaN вручную. Затем мы create, fit & transform a MissingIndicator object который покажет где у нас NaNы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      m1     m3\n",
       "0  False  False\n",
       "1  False  False\n",
       "2   True  False\n",
       "3   True   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "X.replace({999.0 : np.NaN}, inplace=True)\n",
    "\n",
    "# указываем что считать пустым значением (оно может быть только одно)\n",
    "indicator = MissingIndicator(missing_values=np.NaN)\n",
    "indicator = indicator.fit_transform(X)\n",
    "indicator = pd.DataFrame(indicator, columns=['m1', 'm3'])\n",
    "indicator\n",
    "\n",
    "# обрати внимание что второго столбца (в котором нет пустых значений)\n",
    "# в индикаторе нет, он такие столбцы игнорирует, выводя только те в которых\n",
    "# есть хоть одно пустое значение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing values\n",
    "\n",
    "After deciding to keep (some of) your missing values and creating missing value indicators, the next question is if you should replace the missing values. Most learning algorithms perform poorly when missing values are expressed as not a number (np.NaN) and need some form of missing value imputation. Be aware that some libraries and algorithms, such as XGBoost, can handle missing values and impute these values automatically by learning.\n",
    "\n",
    "For filling up missing values with common strategies, sklearn provides a SimpleImputer. The four main strategies are mean, most_frequent, median and constant (don’t forget to set the fill_value parameter). In the example below we impute missing values for our dataframe X with the feature’s mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  7.        ,  8.        ],\n",
       "       [-5.        ,  0.        , 25.        ],\n",
       "       [ 0.        ,  1.        , -1.        ],\n",
       "       [ 0.        ,  0.        , 10.66666667]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit_transform(X)\n",
    "\n",
    "# пустые значения заполнили, однако этот метод возвращает массив NumPy\n",
    "# что для нас не очень полезно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values returned are put into an Numpy array and we lose all the meta-information. Since all these strategies can be mimicked in pandas, we are going to use pandas fillna method to impute missing values. For ‘mean’ we can use the following code. This pandas implementation also provides options to fill forward (ffill) or fill backward (bfill), which are convenient when working with time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2         f3\n",
       "0  5.0  7.0   8.000000\n",
       "1 -5.0  0.0  25.000000\n",
       "2  0.0  1.0  -1.000000\n",
       "3  0.0  0.0  10.666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в пандасе тоже самое можно сделать вот так:\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other popular ways to impute missing data are clustering the data with the k-nearest neighbor (KNN) algorithm or interpolating the values using a wide range of interpolation methods. Both techniques are not implemented in sklearn’s preprocessing library and won’t be discussed here.\n",
    "\n",
    "# Polynomial features\n",
    "\n",
    "Creating polynomial features is a simple and common way of feature engineering that adds complexity to numeric input data by combining features.\n",
    "\n",
    "Polynomial features are often created when we want to include the notion that there exists a nonlinear relationship between the features and the target.They are mostly used to add complexity to linear models with little features, or when we suspect the effect of one feature is dependent on another feature.\n",
    "\n",
    "Before handling missing values, you need to decide if you want to use polynomial features or not. If you for example replace all the missing values by 0, all the cross-products using this feature will be 0. Moreover, if you don’t replace missing values (NaN), creating polynomial features will raise a value error in the fit_transform phase, since the input should be finite.\n",
    "\n",
    "In this respect, replacing missing values by the median or the mean seems to be a reasonable choice. Since I’m not completely sure about this, and can’t find any consistent information, I asked this question on the data science StackExchange.\n",
    "\n",
    "Sklearn provides a PolynomialFeatures class to create polynomial features from scratch. The degree parameter determines the maximum degree of the polynomial. For example, when degree is set to two and X=x1, x2, the features created will be 1, x1, x2, x1², x1x2 and x2². The interaction_only parameter let the function know we only want the interaction features, i.e. 1, x1, x2 and x1x2.\n",
    "\n",
    "Here, we create polynomial features to the third degree and only interaction feature. As a result we get four new features: f1.f2, f1.f3, f2.f3 and f1.f2.f3. Note that our original features are also included in the output and we slice off the new features to add to our data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1     p2    p3     p4\n",
       "0  35.0   40.0  56.0  280.0\n",
       "1  -0.0 -125.0   0.0   -0.0\n",
       "2   0.0   -0.0  -1.0   -0.0\n",
       "3   0.0    0.0   0.0    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "\n",
    "# создали фрейм, запихнули в него polynomial features, сделали срез\n",
    "# чтоб в конечном фрейме были только полиномные features\n",
    "polynomials = pd.DataFrame(poly.fit_transform(X),\n",
    "                           columns=['0','1','2','3',\n",
    "                                    'p1', 'p2', 'p3',\n",
    "                                    'p4'])[['p1', 'p2', 'p3', 'p4']]\n",
    "polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with any other form of feature engineering, it is important to create polynomial features before doing any feature scaling.\n",
    "\n",
    "Now, let’s concatenate our new missing indicator features and polynomial features to our data with pandas concat method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>m1</th>\n",
       "      <th>m3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2         f3     m1     m3    p1     p2    p3     p4\n",
       "0  5.0  7.0   8.000000  False  False  35.0   40.0  56.0  280.0\n",
       "1 -5.0  0.0  25.000000  False  False  -0.0 -125.0   0.0   -0.0\n",
       "2  0.0  1.0  -1.000000   True  False   0.0   -0.0  -1.0   -0.0\n",
       "3  0.0  0.0  10.666667   True   True   0.0    0.0   0.0    0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X, indicator, polynomials], axis='columns')\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical features\n",
    "\n",
    "Munging categorical data is another essential process during data preprocessing. Unfortunately, sklearn’s machine learning library does not support handling categorical data. Even for tree-based models, it is necessary to convert categorical features to a numerical representation.\n",
    "\n",
    "Before you start transforming your data, it is important to figure out if the feature you’re working on is ordinal (as opposed to nominal). An ordinal feature is best described as a feature with natural, ordered categories and the distances between the categories is not known.\n",
    "\n",
    "Once you know what type of categorical data you’re working on, you can pick a suiting transformation tool. In sklearn that will be a OrdinalEncoder for ordinal data, and a OneHotEncoder for nominal data.\n",
    "\n",
    "Let’s consider a simple example to demonstrate how both classes are working. Create a dataframe with five entries and three features: sex, blood type and education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sex blood_type edu_level\n",
      "0   M         O-    medium\n",
      "1   M         O-      high\n",
      "2   F         O+      high\n",
      "3   F         AB       low\n",
      "4   F         B+       NaN\n"
     ]
    }
   ],
   "source": [
    "# создали тестовый фрейм\n",
    "X = pd.DataFrame([['M', 'O-', 'medium'],\n",
    "                 ['M', 'O-', 'high'],\n",
    "                 ['F', 'O+', 'high'],\n",
    "                 ['F', 'AB', 'low'],\n",
    "                 ['F', 'B+', np.nan]])            \n",
    "X.columns = ['sex', 'blood_type', 'edu_level']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно обработать ordinal data, которым является последний столбец. Для этого создаём объект класса Categorical, передав в него столбец который нужно \"категоризировать\", список категорий и установив ordered=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[medium, high, high, low, NaN]\n",
      "Categories (4, object): [missing < low < medium < high]\n",
      "[medium, high, high, low, missing]\n",
      "Categories (4, object): [missing < low < medium < high]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>edu_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>O-</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>O-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>O+</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>AB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>B+</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex blood_type  edu_level\n",
       "0   M         O-          2\n",
       "1   M         O-          3\n",
       "2   F         O+          3\n",
       "3   F         AB          1\n",
       "4   F         B+          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = pd.Categorical(X['edu_level'], \n",
    "                     categories=['missing', 'low', \n",
    "                                 'medium', 'high'], \n",
    "                     ordered=True)\n",
    "\n",
    "# вот так наш объект выглядит сейчас\n",
    "print(cat)\n",
    "\n",
    "# заменим НАНы на 'missing'\n",
    "cat = cat.fillna('missing')\n",
    "print(cat)\n",
    "\n",
    "# через pd.factorize(), which encode the object as an enumerated type or categorical variable,\n",
    "# передав ему наш объект cat (с категориями) и установив sort=True (т.к. у нас ordinal data)\n",
    "# получаем labels и unique - два np.ndarray, один с набором наших категорий для каждого sample\n",
    "# нашего столбца, второй с  набором уникальных категорий\n",
    "labels, unique = pd.factorize(cat, sort=True)\n",
    "\n",
    "# и наконец присваиваем столбцу edu_level эти лейблы, заменяя строки на упорядоченные числовые\n",
    "# значения, делая этот столбец пригодным к использованию в алгоритмах МЛ\n",
    "X['edu_level'] = labels\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо перевести в числа наши nominal данные. Remember that we can’t replace these features by a number since this would imply the features have an order, which is untrue in case of sex or blood type.\n",
    "\n",
    "The most popular way to encode nominal features is one-hot-encoding. Essentially, each categorical feature with n categories is transformed into n binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   F  M  AB  B+  O+  O-\n",
      "0  0  1   0   0   0   1\n",
      "1  0  1   0   0   0   1\n",
      "2  1  0   0   0   1   0\n",
      "3  1  0   1   0   0   0\n",
      "4  1  0   0   1   0   0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>AB</th>\n",
       "      <th>B+</th>\n",
       "      <th>O+</th>\n",
       "      <th>O-</th>\n",
       "      <th>edu_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  M  AB  B+  O+  O-  edu_level\n",
       "0  0  1   0   0   0   1          2\n",
       "1  0  1   0   0   0   1          3\n",
       "2  1  0   0   0   1   0          3\n",
       "3  1  0   1   0   0   0          1\n",
       "4  1  0   0   1   0   0          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# создадим объект класса OneHotEncoder переведя все данные в np.int и выставив sparce=False,\n",
    "# чтоб при onehot.fit_transform() на выходе был обычный массив, а не sparse array,\n",
    "# к\n",
    "onehot = OneHotEncoder(dtype=np.int, sparse=False)\n",
    "\n",
    "# fit & transform our two nominal categoricals.\n",
    "nominals = pd.DataFrame(onehot.fit_transform(X[['sex', 'blood_type']]),\n",
    "                        columns=['F', 'M', 'AB', 'B+','O+', 'O-'])\n",
    "print(nominals) # смотрим что получилось\n",
    "\n",
    "# добавляем столбец edu_level подготовленный ранее\n",
    "nominals['edu_level'] = X['edu_level']\n",
    "nominals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were no missing values in our data, it is important to have a word on how to handle missing values with the OneHotEncoder. A missing value can easily be handled as an extra feature. Note that to do this, you need to replace the missing value by an arbitrary value first (e.g. ‘missing’) If you, on the other hand, want to ignore the missing value and create an instance with all zeros (False), you can just set the handle_unkown parameter of the OneHotEncoder to ignore.\n",
    "\n",
    "# Numerical features\n",
    "\n",
    "Just like categorical data can be encoded, numerical features can be ‘decoded’ into categorical features. The two most common ways to do this are discretization and binarization.\n",
    "\n",
    "$$Discretization$$\n",
    "\n",
    "Discretization, also known as quantization or binning, divides a continuous feature into a pre-specified number of categories (bins), and thus makes the data discrete.\n",
    "\n",
    "One of the main goals of a discretization is to significantly reduce the number of discrete intervals of a continuous attribute. Hence, why this transformation can increase the performance of tree based models.\n",
    "\n",
    "sklearn.preprocessing provides a KBinsDiscretizer class that can take care of this. Important 'strategy' parameter can be set to three values:\n",
    "    \n",
    "    1) uniform, where all bins in each feature have identical widths.\n",
    "    2) quantile (default), where all bins in each feature have the same number of points.\n",
    "    3) kmeans, where all values in each bin have the same nearest center of a 1D k-means cluster.\n",
    "\n",
    "It is important to pick the strategy parameter with care. Using the uniform strategy for example, is very sensitive for outliers and can make you end up with bins with just a few data points, i.e. the outliners.\n",
    "\n",
    "Остальное читай в документации.\n",
    "\n",
    "\n",
    "$$Binarization$$\n",
    "\n",
    "Feature binarization is the process of tresholding numerical features to get boolean values. Or in other words, assign a boolean value (True or False) to each sample based on a threshold. Note that binarization is an extreme form of two-bin discretization.\n",
    "\n",
    "Binarization is useful as a feature engineering technique for creating new features that indicate something meaningful.\n",
    "\n",
    "импортируется он вот так - from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "# Custom transformers\n",
    "\n",
    "Если хотим провернуть какую-то кастомную трансформацию данных то можно использовать FunctionTransformer. Или просто применить лямбда-функцию через df['столбец'].aplly(lamda x: функция(х)).\n",
    "\n",
    "\n",
    "# Feature scaling\n",
    "\n",
    "Следующий логический этап подготовки данных это их скалирование (scaling). Однако есть нюанс, если мы делим наш датасет на тренировочный и тестовый сеты, то их сначала нужно разделить и лишь затем скалировать. Иначе трен-й и тестовый сеты могут оказаться заскейлеными около среднего значения которое не является их средним значением, а является средним значением всего сета. И разделив уже заскейленный сет мы получим трен-й и тестовый сеты которые уже будут незаскейленными. Вот основные виды feature scaling:\n",
    "\n",
    "## Standardization\n",
    "\n",
    "Standardization is a transformation that centers the data by removing the mean value of each feature and then scale it by dividing (non-constant) features by their standard deviation. After standardizing data the mean will be zero and the standard deviation one \n",
    "\n",
    "В sklearn есть куча scalers: StandardScaler, MinMaxScaler, MaxAbsScaler and RobustScaler.\n",
    "\n",
    "Применяются они примерно одинаково:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28562322],\n",
       "       [ 1.53522482],\n",
       "       [-1.24960159],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(.f3.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Normalization is the process of scaling individual samples to have unit norm. In basic terms you need to normalize data when the algorithm predicts based on the weighted relationships formed between data points. Scaling inputs to unit norms is a common operation for text classification or clustering.\n",
    "\n",
    "One of the key differences between scaling (e.g. standardizing) and normalizing, is that normalizing is a row-wise operation, while scaling is a column-wise operation.\n",
    "\n",
    "Although there are many other ways to normalize data, sklearn provides three norms (the value to which the individual values are compared): l1, l2 and max. When creating a new instance of the Normalizer class you can specify the desired norm under the norm parameter.\n",
    "\n",
    "Применяется так же как и стандартизатор.\n",
    "\n",
    "# По применению стандартизаторов и нормализаторов читай документацию"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
